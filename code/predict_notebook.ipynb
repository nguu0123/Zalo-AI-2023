{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "tokenizer_vi2en = AutoTokenizer.from_pretrained(\"vinai/vinai-translate-vi2en-v2\", src_lang=\"vi_VN\")\n",
    "model_vi2en = AutoModelForSeq2SeqLM.from_pretrained(\"vinai/vinai-translate-vi2en-v2\")\n",
    "device_vi2en = torch.device(\"cuda\")\n",
    "model_vi2en.to(device_vi2en)\n",
    "\n",
    "def translate_vi2en(vi_texts: str) -> str:\n",
    "    input_ids = tokenizer_vi2en(vi_texts, padding=True, return_tensors=\"pt\").to(device_vi2en)\n",
    "    output_ids = model_vi2en.generate(\n",
    "        **input_ids,\n",
    "        decoder_start_token_id=tokenizer_vi2en.lang_code_to_id[\"en_XX\"],\n",
    "        num_return_sequences=1,\n",
    "        num_beams=5,\n",
    "        early_stopping=True,\n",
    "        max_length=1024,\n",
    "    )\n",
    "    en_texts = tokenizer_vi2en.batch_decode(output_ids, skip_special_tokens=True)\n",
    "    return en_texts\n",
    "\n",
    "df_test = pd.read_csv(\"../private/info.csv\")\n",
    "df_test['caption'] = df_test['moreInfo'].replace(np.nan, '')\n",
    "df_test['description'] = df_test['moreInfo'].replace(np.nan, '')\n",
    "df_test['moreInfo'] = df_test['moreInfo'].replace(np.nan, '')\n",
    "\n",
    "text_cap = list(df_test['caption'])\n",
    "text_des = list(df_test['description'])\n",
    "text_more_info = list(df_test['moreInfo'])\n",
    "img = list(df_test['bannerImage'])\n",
    "\n",
    "#batch_size = 8\n",
    "eng = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imagen_pytorch import Unet, ImagenTrainer, ElucidatedImagen\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "from imagen_pytorch import t5\n",
    "\n",
    "T5_name = \"google/t5-v1_1-base\"\n",
    "unet1 = Unet(\n",
    "    dim = 128,\n",
    "    cond_dim = 512,\n",
    "    dim_mults = (1, 2, 3, 4),\n",
    "    num_resnet_blocks = 3,\n",
    "    attn_dim_head = 64,\n",
    "    attn_heads = 8,\n",
    "    layer_attns = (False, True, True, True),\n",
    "    layer_cross_attns = (False, True, True, True),\n",
    "    memory_efficient = False,\n",
    ")\n",
    "unet2 = Unet(\n",
    "    dim = 128,\n",
    "    cond_dim = 256, \n",
    "    dim_mults = (1, 2, 3, 4),\n",
    "    num_resnet_blocks = (2, 4, 8, 8),\n",
    "    attn_dim_head = 64,\n",
    "    attn_heads = 8,\n",
    "    layer_attns = (False, False, False, True),\n",
    "    layer_cross_attns = (False, False, False, True),\n",
    "    memory_efficient = True,\n",
    ")\n",
    "imagen = ElucidatedImagen(\n",
    "    unets = [unet1, unet2],\n",
    "    image_sizes = (64, 256),\n",
    "    cond_drop_prob = 0.1,\n",
    "    num_sample_steps = (128, 128),\n",
    "    sigma_min = 0.002,\n",
    "    sigma_max = (80, 160),\n",
    "    sigma_data = 0.5,\n",
    "    rho = 7,\n",
    "    P_mean = -1.2,\n",
    "    P_std = 1.2,\n",
    "    S_churn = 80,\n",
    "    S_tmin = 0.05,\n",
    "    S_tmax = 50,\n",
    "    S_noise = 1.003,\n",
    "    text_encoder_name=T5_name\n",
    ")\n",
    "\n",
    "random_seed = int(random.random() * 1000)\n",
    "trainer = ImagenTrainer(\n",
    "    imagen = imagen,\n",
    ").cuda()\n",
    "\n",
    "trainer.load('../saved_model/model.pt')\n",
    "batch_size = 16\n",
    "stop_unet = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR SUBMISSION 1\n",
    "import time \n",
    "\n",
    "all_predicted_time = []\n",
    "for i in range(0, len(text_cap), batch_size):\n",
    "    t1 = time.time()\n",
    "\n",
    "    if (i + batch_size >= len(text_cap)):\n",
    "        batch_size = len(text_cap) - i\n",
    "        \n",
    "    #input_ = preprocess(prompt)\n",
    "    caption = text_cap[i: i+batch_size]\n",
    "    des = text_des[i: i+batch_size]\n",
    "    img_name = img[i: i+batch_size]\n",
    "    more_info = text_more_info[i: i+batch_size]\n",
    "    all_info = []\n",
    "    for j in range(0, len(caption)):\n",
    "        all_info.append(caption[j] + \". \" + des[j] + \". \" + more_info[j])\n",
    "    trans_text = translate_vi2en(all_info)\n",
    "\n",
    "    #forward = model.generate(trans_text)\n",
    "    info_embeds, mask = t5.t5_encode_text(trans_text, return_attn_mask = True, name=T5_name)\n",
    "    images = trainer.sample(batch_size = batch_size, text_embeds=info_embeds, return_pil_images = True, stop_at_unet_number=stop_unet) # returns List[Image]\n",
    "\n",
    "    for j in range(batch_size):\n",
    "        images[j] = images[j].resize((1024,533))\n",
    "        images[j].save('../results/submission1/jupyter_' + img_name[j])\n",
    "        \n",
    "    #result = postprocess(filename, forward)\n",
    "    t2 = time.time()\n",
    "    predicted_time = t2 - t1\n",
    "    for j in range(batch_size):\n",
    "        all_predicted_time.append((img_name[j], predicted_time/batch_size))\n",
    "    \n",
    "   \n",
    "\n",
    "df_time = pd.DataFrame(all_predicted_time, columns=['fname', 'time'])\n",
    "df_time.to_csv(\"results/time_submission1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR SUBMISSION 2\n",
    "import time \n",
    "\n",
    "all_predicted_time = []\n",
    "for i in range(0, len(text_cap), batch_size):\n",
    "    t1 = time.time()\n",
    "\n",
    "    if (i + batch_size >= len(text_cap)):\n",
    "        batch_size = len(text_cap) - i\n",
    "        \n",
    "    #input_ = preprocess(prompt)\n",
    "    caption = text_cap[i: i+batch_size]\n",
    "    des = text_des[i: i+batch_size]\n",
    "    img_name = img[i: i+batch_size]\n",
    "    more_info = text_more_info[i: i+batch_size]\n",
    "    all_info = []\n",
    "    for j in range(0, len(caption)):\n",
    "        all_info.append(caption[j] + \". \" + des[j] + \". \" + more_info[j])\n",
    "    trans_text = translate_vi2en(all_info)\n",
    "\n",
    "    #forward = model.generate(trans_text)\n",
    "    info_embeds, mask = t5.t5_encode_text(trans_text, return_attn_mask = True, name=T5_name)\n",
    "    images = trainer.sample(batch_size = batch_size, text_embeds=info_embeds, return_pil_images = True, stop_at_unet_number=stop_unet) # returns List[Image]\n",
    "\n",
    "    for j in range(batch_size):\n",
    "        images[j] = images[j].resize((1024,533))\n",
    "        images[j].save('../results/submission2/jupyter_' + img_name[j])\n",
    "        \n",
    "    #result = postprocess(filename, forward)\n",
    "    t2 = time.time()\n",
    "    predicted_time = t2 - t1\n",
    "    for j in range(batch_size):\n",
    "        all_predicted_time.append((img_name[j], predicted_time/batch_size))\n",
    "\n",
    "df_time = pd.DataFrame(all_predicted_time, columns=['fname', 'time'])\n",
    "df_time.to_csv(\"results/time_submission2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
